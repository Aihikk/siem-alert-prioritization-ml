# -*- coding: utf-8 -*-
"""dashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-maLH_rCQPu50ds_hOCf7DoLIghKmxs0

# ðŸ›¡ï¸ SOC Alert Prioritization Dashboard (Streamlit)

This notebook contains a **production-safe Streamlit dashboard** for SIEM alert prioritization with robust SHAP explainability.

âš ï¸ Export this notebook as `dashboard.py` and run with:
`python -m streamlit run dashboard.py`
"""

import streamlit as st
import pandas as pd
import joblib
import shap
import numpy as np

st.set_page_config(page_title="SOC Alert Prioritization Dashboard", layout="wide")
st.title("ðŸ›¡ï¸ SOC Alert Prioritization Dashboard")
st.caption("ML-powered alert triage with explainability for SOC analysts")

@st.cache_resource
def load_model():
    return joblib.load("siem_alert_priority_model.pkl")

model = load_model()
trained_features = model.feature_names_in_

@st.cache_data
def load_data():
    X = pd.read_csv("siem_features.csv")
    alerts = pd.read_csv("siem_alerts.csv")
    return X, alerts

X, alerts = load_data()
X = X.reindex(columns=trained_features, fill_value=0)

alerts["risk_score"] = model.predict_proba(X)[:, 1]

def risk_band(score):
    if score >= 0.7:
        return "HIGH"
    elif score >= 0.4:
        return "MEDIUM"
    else:
        return "LOW"

alerts["risk_level"] = alerts["risk_score"].apply(risk_band)

st.subheader("ðŸ“Š SOC Overview")
c1, c2, c3, c4 = st.columns(4)
c1.metric("Total Alerts", len(alerts))
c2.metric("High Risk Alerts", (alerts["risk_level"] == "HIGH").sum())
c3.metric("Medium Risk Alerts", (alerts["risk_level"] == "MEDIUM").sum())
c4.metric("Low Risk Alerts", (alerts["risk_level"] == "LOW").sum())

st.subheader("ðŸš¨ Prioritized Alert Queue")
alerts_sorted = alerts.sort_values("risk_score", ascending=False)

num_alerts = st.slider("Number of alerts to display", 10, 200, 25, step=5)

st.dataframe(
    alerts_sorted[["alert_type", "user", "destination_host", "risk_level", "risk_score"]]
    .head(num_alerts),
    use_container_width=True,
    hide_index=True
)

st.subheader("ðŸ” Alert Investigation Panel")
alert_index = st.slider("Select alert (by priority order)", 0, len(alerts_sorted) - 1, 0)
selected_alert = alerts_sorted.iloc[alert_index]

colA, colB = st.columns(2)
with colA:
    st.json({
        "Alert Type": selected_alert["alert_type"],
        "User": selected_alert["user"],
        "Destination Host": selected_alert["destination_host"],
        "Risk Level": selected_alert["risk_level"],
        "Risk Score": round(float(selected_alert["risk_score"]), 3)
    })

with colB:
    if selected_alert["risk_level"] == "HIGH":
        st.error("Immediate investigation required. Possible incident.")
    elif selected_alert["risk_level"] == "MEDIUM":
        st.warning("Review recommended. Monitor for escalation.")
    else:
        st.success("Low risk. Can be deprioritized.")

st.subheader("ðŸ§  Why was this alert classified this way?")

original_index = alerts_sorted.index[alert_index]
X_alert = X.loc[[original_index]]

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_alert, check_additivity=False)

if isinstance(shap_values, list):
    alert_shap = shap_values[1][0]
else:
    alert_shap = shap_values[0]

alert_shap = np.array(alert_shap).flatten()

# Align SHAP values safely with feature list
min_len = min(len(X.columns), len(alert_shap))

shap_df = pd.DataFrame({
    "Feature": X.columns[:min_len],
    "Feature Value": X_alert.iloc[0].values[:min_len],
    "SHAP Value": alert_shap[:min_len]
})


shap_df["Impact"] = shap_df["SHAP Value"].abs()
shap_df["Effect"] = np.where(shap_df["SHAP Value"] > 0, "Increases Risk", "Reduces Risk")

top_shap = shap_df.sort_values("Impact", ascending=False).head(5)

st.dataframe(top_shap[["Feature", "Feature Value", "Effect", "SHAP Value"]],
             use_container_width=True)